{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.activation import ReLU, SoftMax\n",
    "from src.classifier import FullyConnected\n",
    "from src.conv2d import Conv2d\n",
    "from src.dropout import Dropout\n",
    "from src.flatten import Flatten\n",
    "from src.loss import SoftmaxCrossEntropy\n",
    "from src.nn import NeuralNetwork\n",
    "from src.optimizer import RAdam\n",
    "from src.pool2d import Pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def one_hot(x, num_classes=10):\n",
    "    out = np.zeros((x.shape[0], num_classes))\n",
    "    out[np.arange(x.shape[0]), x[:, 0]] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "def preprocess(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(np.float32)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(np.float32)\n",
    "    y_train = one_hot(y_train.reshape(y_train.shape[0], 1))\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    return x_train, y_train, x_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully downloaded\n",
      "Train mode:\n",
      "  Batch size is 256, learning rate is 0.001\n",
      "\n",
      "Epoch 1\n",
      "Done 5.5% / 100%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 25>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset successfully downloaded\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m cnn \u001B[38;5;241m=\u001B[39m NeuralNetwork(\n\u001B[1;32m     11\u001B[0m     input_dim\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m     12\u001B[0m     layers\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mRAdam\n\u001B[1;32m     23\u001B[0m )\n\u001B[0;32m---> 25\u001B[0m \u001B[43mcnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmini_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m          \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m          \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m y_predict \u001B[38;5;241m=\u001B[39m cnn\u001B[38;5;241m.\u001B[39mpredict(x_test)\n\u001B[1;32m     32\u001B[0m y_predict \u001B[38;5;241m=\u001B[39m y_predict\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/ML models/numpyCNN/src/nn.py:81\u001B[0m, in \u001B[0;36mNeuralNetwork.train\u001B[0;34m(self, x_train, y_train, mini_batch_size, learning_rate, num_epochs, validation_data)\u001B[0m\n\u001B[1;32m     79\u001B[0m     mini_batch_x, mini_batch_y \u001B[38;5;241m=\u001B[39m mini_batch\n\u001B[1;32m     80\u001B[0m     step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 81\u001B[0m     epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmini_batch_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmini_batch_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m mini_batch_size\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;124mDone \u001B[39m\u001B[38;5;132;01m{:1.1%}\u001B[39;00m\u001B[38;5;124m / 100\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i \u001B[38;5;241m/\u001B[39m num_mini_batches), end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTrain loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/ML models/numpyCNN/src/nn.py:93\u001B[0m, in \u001B[0;36mNeuralNetwork.train_step\u001B[0;34m(self, x_train, y_train, learning_rate, step)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_train, y_train, learning_rate, step):\n\u001B[0;32m---> 93\u001B[0m     a_last \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_prop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackward_prop(a_last, y_train)\n\u001B[1;32m     95\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss(a_last, y_train)\n",
      "File \u001B[0;32m~/Desktop/ML models/numpyCNN/src/nn.py:26\u001B[0m, in \u001B[0;36mNeuralNetwork.forward_prop\u001B[0;34m(self, x, training)\u001B[0m\n\u001B[1;32m     24\u001B[0m a \u001B[38;5;241m=\u001B[39m x\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 26\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "File \u001B[0;32m~/Desktop/ML models/numpyCNN/src/conv2d.py:44\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, a_prev, training)\u001B[0m\n\u001B[1;32m     41\u001B[0m         h_start \u001B[38;5;241m=\u001B[39m j \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride\n\u001B[1;32m     42\u001B[0m         h_end \u001B[38;5;241m=\u001B[39m h_start \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_size\n\u001B[0;32m---> 44\u001B[0m         out[:, i, j, :] \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma_prev_padded\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv_start\u001B[49m\u001B[43m:\u001B[49m\u001B[43mv_end\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_start\u001B[49m\u001B[43m:\u001B[49m\u001B[43mh_end\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnewaxis\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\n\u001B[1;32m     45\u001B[0m \u001B[43m                                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnewaxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m z \u001B[38;5;241m=\u001B[39m out \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbiases\n\u001B[1;32m     48\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation\u001B[38;5;241m.\u001B[39mf(z)\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36msum\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2298\u001B[0m, in \u001B[0;36msum\u001B[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[1;32m   2295\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[1;32m   2296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[0;32m-> 2298\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2299\u001B[0m \u001B[43m                      \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     84\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[0;32m---> 86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mufunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpasskwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "x_train = mnist.train_images()\n",
    "x_test = mnist.test_images()\n",
    "y_train = mnist.train_labels()\n",
    "y_test = mnist.test_labels()\n",
    "\n",
    "x_train, y_train, x_test, y_test = preprocess(x_train, y_train, x_test, y_test)\n",
    "print(\"Dataset successfully downloaded\")\n",
    "\n",
    "\n",
    "cnn = NeuralNetwork(\n",
    "    input_dim=(28, 28, 1),\n",
    "    layers=[\n",
    "        Conv2d(5, 1, 32, activation=ReLU()),\n",
    "        Pool2d(2, 2, 'max'),\n",
    "        Dropout(0.75),\n",
    "        Flatten(),\n",
    "        FullyConnected(128, ReLU()),\n",
    "        Dropout(0.9),\n",
    "        FullyConnected(10, SoftMax()),\n",
    "    ],\n",
    "    loss_function=SoftmaxCrossEntropy(),\n",
    "    optimizer=RAdam\n",
    ")\n",
    "\n",
    "cnn.train(x_train, y_train,\n",
    "          mini_batch_size=256,\n",
    "          learning_rate=0.001,\n",
    "          num_epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "y_predict = cnn.predict(x_test)\n",
    "y_predict = y_predict.argmax(axis=1)\n",
    "print(\"F1 macro metrics:\")\n",
    "print(f1_score(y_test, y_predict, average='macro'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}